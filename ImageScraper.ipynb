{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ImageScraper",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMq8DetAEB1eok8EUHnRypn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joedockrill/image-scraper/blob/master/ImageScraper.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zga2kYYG1b4R",
        "colab_type": "text"
      },
      "source": [
        "**Image Scraper**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OVwjN8fnD5kc",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Code setup, RUN THIS CELL.\n",
        "#@markdown This notebook can scrape from Google and DuckDuckGo, but the results from DuckDuckGo  \n",
        "#@markdown are much better. The thumbnails are much larger and the results include the original \n",
        "#@markdown (even bigger) url (although I don't currently use it).\n",
        "#@markdown \n",
        "#@markdown I've really only left the Google scraping here in case the DuckDuckGo code breaks in the \n",
        "#@markdown future so there's something else here which works.\n",
        "#@markdown \n",
        "#@markdown I'd also love to add params for DuckDuckGo to constrain searches by layouts and \n",
        "#@markdown colours etc like you can do in the GUI but I can't currently see how to do this via their \n",
        "#@markdown i.js interface and it's completely undocumented. Check back later.\n",
        "#@markdown \n",
        "#@markdown If you're new to colab and you want to see the code, click on the ... menu in the top\n",
        "#@markdown right of this cell and click \"Form\" then \"Hide Form\"\n",
        "#@markdown \n",
        "#@markdown Workflow:\n",
        "#@markdown - Write some search functions in the \"Download your images here\" cell\n",
        "#@markdown - Run the image cleaner to delete rubbish\n",
        "#@markdown - Zip it all up\n",
        "#@markdown - Download it or copy it to Google Drive\n",
        "#@markdown \n",
        "#@markdown Feel free to copy/share/modify as you see fit.\n",
        "#@markdown \n",
        "#@markdown Hugs & kisses, Joe Dockrill. \n",
        "#@markdown \n",
        "#@markdown credits: https://github.com/deepanprabhu/duckduckgo-images-api for the base DuckDuckGo code\n",
        "#@markdown \n",
        "import os\n",
        "import requests\n",
        "import re\n",
        "import json\n",
        "import time\n",
        "from bs4 import BeautifulSoup\n",
        "from PIL import Image\n",
        "import ipywidgets as widgets\n",
        "from ipywidgets import interactive\n",
        "from IPython.display import display\n",
        "import shutil\n",
        "\n",
        "BASE_FOLDER = \"images\"\n",
        "\n",
        "def google_scrape_urls(keywords, max_results):\n",
        "  BASE_URL = \"https://www.google.com/search?site=&tbm=isch&source=hp&biw=1873&bih=990&q=\"\n",
        "\n",
        "  HEADERS = {\n",
        "      'User-Agent': 'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.11 (KHTML, like Gecko) Chrome/23.0.1271.64 Safari/537.11',\n",
        "      'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',\n",
        "      'Accept-Charset': 'ISO-8859-1,utf-8;q=0.7,*;q=0.3',\n",
        "      'Accept-Encoding': 'none',\n",
        "      'Accept-Language': 'en-US,en;q=0.8',\n",
        "      'Connection': 'keep-alive',\n",
        "  }\n",
        "  \n",
        "  searchurl = BASE_URL + keywords\n",
        "  resp = requests.get(searchurl, headers=HEADERS)\n",
        "  html = resp.text\n",
        "  \n",
        "  soup = BeautifulSoup(html, \"html.parser\")\n",
        "  results = soup.findAll(\"img\", {\"data-src\":True}, limit=max_results)\n",
        "  \n",
        "  links = []\n",
        "  for re in results:\n",
        "    links.append(re[\"data-src\"])\n",
        "\n",
        "  return links  \n",
        "  \n",
        "def duckduckgo_scrape_urls(keywords, max_results):\n",
        "    BASE_URL = 'https://duckduckgo.com/'\n",
        "    params = {\n",
        "    \t'q': keywords\n",
        "    };\n",
        "    results = 0\n",
        "    links = []\n",
        "\n",
        "    resp = requests.post(BASE_URL, data=params)\n",
        "    match = re.search(r'vqd=([\\d-]+)\\&', resp.text, re.M|re.I)\n",
        "    assert match is not None, \"Failed to obtain search token\"\n",
        "\n",
        "    HEADERS = {\n",
        "        'authority': 'duckduckgo.com',\n",
        "        'accept': 'application/json, text/javascript, */*; q=0.01',\n",
        "        'sec-fetch-dest': 'empty',\n",
        "        'x-requested-with': 'XMLHttpRequest',\n",
        "        'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_4) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.163 Safari/537.36',\n",
        "        'sec-fetch-site': 'same-origin',\n",
        "        'sec-fetch-mode': 'cors',\n",
        "        'referer': 'https://duckduckgo.com/',\n",
        "        'accept-language': 'en-US,en;q=0.9',\n",
        "    }\n",
        "\n",
        "    PARAMS = (\n",
        "        ('l', 'us-en'),\n",
        "        ('o', 'json'),\n",
        "        ('q', keywords),\n",
        "        ('vqd', match.group(1)),\n",
        "        ('f', ',,,'),\n",
        "        ('p', '1'),\n",
        "        ('v7exp', 'a'),\n",
        "    )\n",
        "\n",
        "    requestUrl = BASE_URL + \"i.js\"\n",
        "\n",
        "    while True:\n",
        "        while True:\n",
        "            try:\n",
        "                resp = requests.get(requestUrl, headers=HEADERS, params=PARAMS)\n",
        "                data = json.loads(resp.text)\n",
        "                break\n",
        "            except ValueError as e:\n",
        "                print(\"Hit request throttle, sleeping and retrying\")\n",
        "                time.sleep(5); #seems a lot but ok...\n",
        "                continue\n",
        "\n",
        "        #result[\"thumbnail\"] is normally big enough for most purposes\n",
        "        #result[\"width\"], result[\"height\"] are for the full size img in result[\"image\"]\n",
        "        #result[\"image\"] url to full size img on orig site (so may be less reliable) \n",
        "        #result[\"url\"], result[\"title\"].encode('utf-8') from the page the img came from\n",
        "        \n",
        "        for result in data[\"results\"]:\n",
        "          links.append(result[\"thumbnail\"])\n",
        "          if(max_results is not None):\n",
        "            if(len(links) >= max_results) : return links\n",
        "  \n",
        "        if \"next\" not in data:\n",
        "            #no next page, all done\n",
        "            return links\n",
        "\n",
        "        requestUrl = BASE_URL + data[\"next\"]\n",
        "\n",
        "def download_urls(label, links):\n",
        "  if(len(links) == 0):\n",
        "    print(\"Nothing to download!\"); return\n",
        "\n",
        "  print(\"Downloading\", len(links), \"images for\", label)\n",
        "\n",
        "  folder = os.path.join(BASE_FOLDER, label)\n",
        "  if not os.path.exists(folder): os.makedirs(folder)\n",
        "\n",
        "  bar = widgets.IntProgress(0, 0, len(links) - 1)\n",
        "  display(bar)\n",
        "\n",
        "  for i, link in enumerate(links):\n",
        "      resp = requests.get(link)      \n",
        "      filename = os.path.join(folder, label + str(i+1).zfill(3) + \".jpg\")\n",
        "      with open(filename, \"wb\") as file:\n",
        "          file.write(resp.content)\n",
        "\n",
        "      try:\n",
        "        img = Image.open(filename)\n",
        "        img.verify()\n",
        "        img.close()\n",
        "      except:\n",
        "        print(filename, \"is invalid\")\n",
        "        shutil.os.remove(filename)\n",
        "\n",
        "      bar.value += 1\n",
        "\n",
        "  bar.bar_style = \"success\"\n",
        "\n",
        "def google_search(label, keywords, max_results=100):\n",
        "  links = google_scrape_urls(keywords,max_results)\n",
        "  download_urls(label, links)\n",
        "\n",
        "def duckduckgo_search(label, keywords, max_results=100):\n",
        "  links = duckduckgo_scrape_urls(keywords,max_results)\n",
        "  download_urls(label, links)\n"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tTCCj9TS0WVY",
        "colab_type": "text"
      },
      "source": [
        "**Run this cell to delete all image files (to create another dataset or reset)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EYwHbopFG63A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -r images/*"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j4dwxx_b0pRV",
        "colab_type": "text"
      },
      "source": [
        "**Download your images here**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vw7K4ULGz-8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DATASET_NAME = \"images\" #change this to something more meaningful\n",
        "duckduckgo_search(\"label\", \"query keywords\", max_results=100)\n",
        "\n",
        "# EG:\n",
        "# DATASET_NAME = \"Clowns\"\n",
        "# duckduckgo_search(\"Nice\", \"nice clowns\", max_results=150)\n",
        "# duckduckgo_search(\"Scary\", \"scary clowns\", max_results=150)\n",
        "\n",
        "# you can also use google_search() if you prefer or if the ddg code breaks.\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Me-dTEWUKn3C",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Quick & Dirty Dataset Cleaner \n",
        "#@markdown Run this cell for a quick image cleaner. When you hit delete it's done immediately but you'll need to run the cell again or swap folders to refresh the view.\n",
        "\n",
        "#@markdown This is SLOW at loading more than a handful of images. I assume it would be a decent bit faster if it was running locally. \n",
        "\n",
        "def click_handler(btn):\n",
        "  shutil.os.remove(btn.tag)\n",
        "  btn.disabled = True\n",
        "\n",
        "def render_image_cleaner(folder):\n",
        "  items = []\n",
        "  path = os.path.join(BASE_FOLDER, folder)\n",
        "  \n",
        "  for filename in os.listdir(path):\n",
        "      if filename.endswith(\".jpg\"):\n",
        "          file = open(os.path.join(path, filename), \"rb\")\n",
        "          fstream = file.read()\n",
        "          img = widgets.Image(value=fstream, format='jpg')\n",
        "          img.layout.width=\"150px\"\n",
        "          btn = widgets.Button(description=\"Delete\")\n",
        "          btn.tag = os.path.join(path, filename)\n",
        "          btn.on_click(click_handler)\n",
        "          box = widgets.VBox(children=(img,btn))\n",
        "          box.layout.margin = \"5px\"\n",
        "          items.append(box)\n",
        "  \n",
        "  grid = widgets.GridBox(items, layout=widgets.Layout(grid_template_columns=\"repeat(4, 25%)\"))\n",
        "  grid.layout.margin = \"15px\"\n",
        "  display(grid)\n",
        "\n",
        "folders = next(os.walk(BASE_FOLDER))[1]\n",
        "folders.sort()\n",
        "\n",
        "w = interactive(render_image_cleaner, folder=folders)\n",
        "display(w)\n",
        "display(w.children[0]) # dropdown top & bottom"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H6KTdjEY0Fix",
        "colab_type": "text"
      },
      "source": [
        "**Run this cell to create a zip file**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O8CT2yVzfZXb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm {DATASET_NAME}.zip\n",
        "!zip -r {DATASET_NAME}.zip images"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kmtxy9LX2M1J",
        "colab_type": "text"
      },
      "source": [
        "**Run one of these cells to get your zip file**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rmnndlPN1yTY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#download to your local system\n",
        "from google.colab import files\n",
        "files.download(DATASET_NAME + \".zip\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-BfkU4_u2kdp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#copy to google drive (Datasets folder by default, change below)\n",
        "from google.colab import drive\n",
        "import shutil\n",
        "\n",
        "DRIVE_DEST_FOLDER = \"Datasets\"\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "folder = os.path.join(\"/content/drive/My Drive\", DRIVE_DEST_FOLDER)\n",
        "if not os.path.exists(folder): os.makedirs(folder)\n",
        "\n",
        "shutil.copyfile(DATASET_NAME + \".zip\", os.path.join(folder, DATASET_NAME + \".zip\"))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}